{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:/Users/tln229/Downloads/data process Peak/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while processing H3K36me3_TDH_immune/samples/tcell/McGill0024/problems/chr10:51448845-125869472: Error -3 while decompressing data: invalid code lengths set\n"
     ]
    }
   ],
   "source": [
    "compress_length = 5000\n",
    "compress_type = \"Piecewise_Aggregation_Approximation\"\n",
    "\n",
    "for data in list_files(data_dir):\n",
    "    for sample in list_files(data_dir + data + \"/samples\"):\n",
    "        for problem in list_files(data_dir + data + \"/samples/\" + sample):\n",
    "            for chr in list_files(data_dir + data + \"/samples/\" + sample + \"/\" + problem + \"/problems\"):\n",
    "                sequenceID = data + \"/samples/\" + sample + \"/\" + problem + \"/problems/\" + chr.replace('_', ':')\n",
    "                try:\n",
    "                    sequence_path = data_dir + data + \"/samples/\" + sample + \"/\" + problem + \"/problems/\" + chr + \"/coverage.bedGraph.gz\"\n",
    "                    extracted_file = sequence_path.replace('.gz', '')\n",
    "\n",
    "                    # Open the compressed file and read the content\n",
    "                    with gzip.open(sequence_path, 'rb') as f_in:\n",
    "                        with open(extracted_file, 'wb') as f_out:\n",
    "                            f_out.write(f_in.read())\n",
    "\n",
    "                    # Load the data into a Pandas DataFrame\n",
    "                    df = pd.read_csv(extracted_file, sep='\\t', header=None, names=['value'])\n",
    "\n",
    "                    # Reset the index to avoid any issues with the current index\n",
    "                    df = df.reset_index(drop=True)\n",
    "\n",
    "                    num_rows = len(df)\n",
    "                    \n",
    "                    # If the number of rows is greater than the target length, compress it to that length\n",
    "                    if num_rows > compress_length:\n",
    "                        # Determine the window size needed to reduce the data to compress_length rows\n",
    "                        window_size = num_rows // compress_length\n",
    "                        compact_df = df.groupby(df.index // window_size).mean().head(compress_length).reset_index(drop=True)\n",
    "                    else:\n",
    "                        # If the number of rows is already <= compress_length, no need to compress, just copy the data\n",
    "                        compact_df = df.copy()\n",
    "\n",
    "                    # Rename the column 'value' to 'signal'\n",
    "                    compact_df.rename(columns={'value': 'signal'}, inplace=True)\n",
    "\n",
    "                    # Add the 'sequenceID' column\n",
    "                    compact_df.insert(0, 'sequenceID', sequenceID)\n",
    "\n",
    "                    # Define the output file name\n",
    "                    output_file = f'{data}/{compress_type}/{compress_length}/profiles.csv'\n",
    "                    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "                    # Check if the file already exists to decide whether to write the header\n",
    "                    file_exists = os.path.isfile(output_file)\n",
    "\n",
    "                    # Save the compacted DataFrame to a CSV file, with header only if the file doesn't exist\n",
    "                    compact_df.to_csv(output_file, mode='a', header=not file_exists, index=False)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred while processing {sequenceID}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
