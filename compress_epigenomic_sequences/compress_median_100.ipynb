{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:/Users/Tung/Downloads/0.DATA/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: For data 'ATAC_JV_adipose', the number of original sequences (465) matches the number of output sequences (465).\n",
      "Success: For data 'CTCF_TDH_ENCODE', the number of original sequences (182) matches the number of output sequences (182).\n",
      "Success: For data 'H3K27ac-H3K4me3_TDHAM_BP', the number of original sequences (2008) matches the number of output sequences (2008).\n",
      "Success: For data 'H3K27ac_TDH_some', the number of original sequences (95) matches the number of output sequences (95).\n",
      "Success: For data 'H3K27me3_RL_cancer', the number of original sequences (171) matches the number of output sequences (171).\n",
      "Success: For data 'H3K27me3_TDH_some', the number of original sequences (43) matches the number of output sequences (43).\n",
      "Success: For data 'H3K36me3_AM_immune', the number of original sequences (420) matches the number of output sequences (420).\n",
      "Success: For data 'H3K36me3_TDH_ENCODE', the number of original sequences (78) matches the number of output sequences (78).\n",
      "An error occurred while processing H3K36me3_TDH_immune/samples/tcell/McGill0024/problems/chr10:51448845-125869472: Error -3 while decompressing data: invalid code lengths set\n",
      "Success: For data 'H3K36me3_TDH_immune', the number of original sequences (37) matches the number of output sequences (37).\n",
      "Success: For data 'H3K36me3_TDH_other', the number of original sequences (40) matches the number of output sequences (40).\n",
      "Success: For data 'H3K4me1_TDH_BP', the number of original sequences (144) matches the number of output sequences (144).\n",
      "Success: For data 'H3K4me3_PGP_immune', the number of original sequences (297) matches the number of output sequences (297).\n",
      "Success: For data 'H3K4me3_TDH_ENCODE', the number of original sequences (75) matches the number of output sequences (75).\n",
      "Success: For data 'H3K4me3_TDH_immune', the number of original sequences (378) matches the number of output sequences (378).\n",
      "Success: For data 'H3K4me3_TDH_other', the number of original sequences (90) matches the number of output sequences (90).\n",
      "Success: For data 'H3K4me3_XJ_immune', the number of original sequences (270) matches the number of output sequences (270).\n",
      "Success: For data 'H3K9me3_TDH_BP', the number of original sequences (120) matches the number of output sequences (120).\n"
     ]
    }
   ],
   "source": [
    "compress_window = 100  # Example value, adjust as needed\n",
    "compress_type = \"median\"  # Example value, adjust as needed\n",
    "\n",
    "for data in list_files(data_dir):\n",
    "    original_sequence_count = 0  # Reset counter for each data directory\n",
    "    output_sequence_count = 0  # Reset counter for each data directory\n",
    "\n",
    "    for sample in list_files(data_dir + data + \"/samples\"):\n",
    "        for problem in list_files(data_dir + data + \"/samples/\" + sample):\n",
    "            for chr in list_files(data_dir + data + \"/samples/\" + sample + \"/\" + problem + \"/problems\"):\n",
    "                sequenceID = data + \"/samples/\" + sample + \"/\" + problem + \"/problems/\" + chr.replace('_', ':')\n",
    "                try:\n",
    "                    sequence_path = data_dir + data + \"/samples/\" + sample + \"/\" + problem + \"/problems/\" + chr + \"/coverage.bedGraph.gz\"\n",
    "                    extracted_file = sequence_path.replace('.gz', '')\n",
    "\n",
    "                    # Open the compressed file and read the content\n",
    "                    with gzip.open(sequence_path, 'rb') as f_in:\n",
    "                        with open(extracted_file, 'wb') as f_out:\n",
    "                            f_out.write(f_in.read())\n",
    "                    \n",
    "                    # Load the data into a Pandas DataFrame\n",
    "                    df = pd.read_csv(extracted_file, sep='\\t', header=None, names=['value'])\n",
    "\n",
    "                    # Reset the index to remove any MultiIndex issues\n",
    "                    df = df.reset_index(drop=True)\n",
    "\n",
    "                    # Increment the original sequence count\n",
    "                    original_sequence_count += 1\n",
    "\n",
    "                    # Check if the dataframe length is smaller than compress_window\n",
    "                    if len(df) <= compress_window:\n",
    "                        print(f\"Sequence {sequenceID} is smaller than compress_window. Keeping original sequence.\")\n",
    "\n",
    "                        # Keeping the original sequence without compression\n",
    "                        compact_df = df.copy()\n",
    "\n",
    "                    else:\n",
    "                        # Group by every compress_window rows and calculate the mean value for each group\n",
    "                        compact_df = df.groupby(df.index // compress_window).median().reset_index(drop=True)\n",
    "                        \n",
    "                        # If compression does not reduce the size, keep the original sequence\n",
    "                        if len(compact_df) >= len(df):\n",
    "                            print(f\"Compression failed for {sequenceID}. Keeping original sequence.\")\n",
    "                            compact_df = df.copy()\n",
    "\n",
    "                    # Rename the column 'value' to 'signal'\n",
    "                    compact_df.rename(columns={'value': 'signal'}, inplace=True)\n",
    "\n",
    "                    # Add the 'sequenceID' column\n",
    "                    compact_df.insert(0, 'sequenceID', sequenceID)\n",
    "\n",
    "                    # Define the output file name\n",
    "                    output_file = f'{data}/{compress_type}/{compress_window}/profiles.csv'\n",
    "                    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "                    # Check if the file already exists to decide whether to write the header\n",
    "                    file_exists = os.path.isfile(output_file)\n",
    "\n",
    "                    # Save the compacted (or original) DataFrame to a CSV file with header only if the file doesn't exist\n",
    "                    compact_df.to_csv(output_file, mode='a', header=not file_exists, index=False)\n",
    "\n",
    "                    # Increment the output sequence count\n",
    "                    output_sequence_count += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred while processing {sequenceID}: {e}\")\n",
    "\n",
    "    # After processing all sequences for this data, check if the counts match\n",
    "    if original_sequence_count == output_sequence_count:\n",
    "        print(f\"Success: For data '{data}', the number of original sequences ({original_sequence_count}) matches the number of output sequences ({output_sequence_count}).\")\n",
    "    else:\n",
    "        print(f\"Warning: For data '{data}', mismatch between original sequences ({original_sequence_count}) and output sequences ({output_sequence_count}).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
